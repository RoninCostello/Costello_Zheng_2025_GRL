{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a7230d0-1723-4d88-8133-5da007527596",
   "metadata": {},
   "source": [
    "Bin CMIP6 3D meteorological variable data by distance from sea ice edges in a selected Arctic region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dff848c6-63e4-441f-b32f-bfc3ca8c1865",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from scipy.interpolate import griddata\n",
    "import regionmask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b46f0cf5-9341-41d0-a7f9-d0c1422b8962",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:7: FutureWarning: 'M' is deprecated and will be removed in a future version. Please use 'ME' instead of 'M'.\n",
      "<string>:7: FutureWarning: 'M' is deprecated and will be removed in a future version. Please use 'ME' instead of 'M'.\n",
      "<string>:7: FutureWarning: 'M' is deprecated and will be removed in a future version. Please use 'ME' instead of 'M'.\n"
     ]
    }
   ],
   "source": [
    "# Load model cloud fraction data and ensure time is CF-compliant\n",
    "f = xr.open_dataset('/home/rcostell/Model_Files/CMIP6/Historical/Cloud_Fraction_3D/Raw_Output/clcalipso_CFmon_GFDL-CM4_historical_r1i1p1f1_gr1_195001-201412.nc')\n",
    "f['time'] = xr.decode_cf(f)['time']\n",
    "\n",
    "f = f.sel(time=slice('2007', '2014'))\n",
    "f = f.resample(time='1M').mean()\n",
    "\n",
    "lat0 = 60\n",
    "lat1 = 90\n",
    "\n",
    "# Convert longitudes to [-180, 180] for consistent mapping\n",
    "f.coords['lon'] = (f.coords['lon'] + 180) % 360 - 180\n",
    "sorted_indices = np.argsort(f.lon.values)\n",
    "f = f.isel(lon=sorted_indices)\n",
    "\n",
    "f = f.sel(lat = slice(lat0, lat1))\n",
    "lon_plot = f.lon.values\n",
    "lat_plot = f.lat.values\n",
    "\n",
    "# Apply a land mask to retain ocean grid cells only\n",
    "land_mask = regionmask.defined_regions.natural_earth_v5_0_0.land_110.mask(lon_plot, lat_plot)\n",
    "f = f.where(land_mask != 0)\n",
    "\n",
    "# Load filtered and regridded sea ice concentration data - can be a raw file as well\n",
    "filename_si_nh = '/home/rcostell/Model_Files/CMIP6/Historical/Filtered_Sea_Ice_Concentration/GFDL_Filtered_Sea_Ice.nc'\n",
    "f_si_nh = xr.open_dataset(filename_si_nh)\n",
    "f_si_nh['time'] = xr.decode_cf(f_si_nh)['time']\n",
    "\n",
    "# Compute monthly means\n",
    "f_si_nh = f_si_nh.sel(time=slice('2007', '2014'))\n",
    "f_si_nh = f_si_nh.resample(time='1M').mean()\n",
    "\n",
    "# Standardize longitudes to [-180, 180] and ensure increasing order\n",
    "f_si_nh.coords['lon'] = (f_si_nh.coords['lon'] + 180) % 360 - 180\n",
    "f_si_nh = f_si_nh.sortby(f_si_nh.lon)\n",
    "\n",
    "# Interpolate sea ice data to the same grid as the cloud fraction dataset\n",
    "f_si_nh = f_si_nh.interp(lat=lat_plot, lon=lon_plot)\n",
    "\n",
    "si_winter_nh = f_si_nh.sel(lat=slice(lat0, lat1))\n",
    "\n",
    "land_mask = regionmask.defined_regions.natural_earth_v5_0_0.land_110.mask(lon_plot, lat_plot)\n",
    "\n",
    "f0 = si_winter_nh.where(land_mask != 0)\n",
    "\n",
    "# Match sea ice time steps to the cloud fraction dataset\n",
    "ind = []\n",
    "for i, d in enumerate(f.time.values):\n",
    "    tmp = np.where(f0.time.values == d)[0]\n",
    "    ind.append(tmp[0])\n",
    "\n",
    "ind = np.array(ind)\n",
    "\n",
    "f0 = f0.isel(time = ind).sea_ice_concentration\n",
    "f = f.assign(seaice_conc=f0)\n",
    "\n",
    "#Attaching another 3D variable like air temperature\n",
    "f1 = xr.open_dataset('/home/rcostell/Model_Files/CMIP6/Historical/Air_Temperature/Raw_Output/ta_Amon_GFDL-ESM4_historical_r1i1p1f1_gr1_195001-201412.nc')\n",
    "\n",
    "f1['time'] = xr.decode_cf(f1)['time']\n",
    "f1 = f1.sel(time=slice('2007', '2014'))\n",
    "f1 = f1.resample(time='1M').mean()\n",
    "\n",
    "f1.coords['lon'] = (f1.coords['lon'] + 180) % 360 - 180\n",
    "f1 = f1.interp(lat=lat_plot, lon=lon_plot)\n",
    "f1 = f1.sel(lat=slice(lat0, lat1))\n",
    "\n",
    "xgrid_nh = f1.lon.values\n",
    "ygrid_nh = f1.lat.values\n",
    "land_mask = regionmask.defined_regions.natural_earth_v5_0_0.land_110.mask(xgrid_nh, ygrid_nh)\n",
    "f1 = f1.where(land_mask != 0)\n",
    "\n",
    "f1 = f1.isel(time=ind).ta\n",
    "f1['time'] = f.time\n",
    "f = f.assign(air=f1)\n",
    "\n",
    "f = f.sel(lon=slice(-15, 55))\n",
    "\n",
    "ice_achv = f.seaice_conc.values/100\n",
    "\n",
    "#Extract key variables\n",
    "cl_achv = f.clcalipso.values\n",
    "air_achv = f.air.values\n",
    "\n",
    "#Retrieve coordinate and dimension arrays\n",
    "lat = f.lat.values\n",
    "lon = f.lon.values\n",
    "time = f.time.values \n",
    "level = f.plev.values\n",
    "altitude = f.alt40.values/1000.\n",
    "\n",
    "# Define array dimensions for later loops or reshaping\n",
    "nlat = len(lat)\n",
    "nlon = len(lon)\n",
    "ntime = len(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a11c0d18-d97e-414a-ab20-f0a9e1a4e175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Binning_distance_from_ice_edge(ice_achv, var_achv, ntime, nlat, nlon, hem, \n",
    "                                   outputcount=False, model=True):\n",
    "    \"\"\"\n",
    "    Bins a 2D or 3D meteorological variable (e.g., cloud fraction) relative to \n",
    "    the sea ice edge for each time step and longitude.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ice_achv : np.ndarray\n",
    "        Sea ice concentration array with dimensions [time, lat, lon].\n",
    "        Values should range from 0 to 1 (0% to 100% divided by 100).\n",
    "    var_achv : np.ndarray\n",
    "        Meteorological variable (e.g., cloud fraction, temperature) array. \n",
    "        Expected dimensions are:\n",
    "          - [time, lat, lon] for 2D variables, or \n",
    "          - [time, level, lat, lon] for 3D variables.\n",
    "    ntime : int\n",
    "        Number of time steps to process.\n",
    "    nlat : int\n",
    "        Number of latitude points.\n",
    "    nlon : int\n",
    "        Number of longitude points.\n",
    "    hem : str\n",
    "        Hemisphere flag: \n",
    "          - 'nh' for Northern Hemisphere (sea ice = 1 → ice-covered)\n",
    "          - 'sh' for Southern Hemisphere (sea ice = 1 → ocean-covered)\n",
    "        Used to determine which side of the ice edge is \"ice\" vs \"ocean\".\n",
    "    outputcount : bool, optional\n",
    "        If True, also return the count array that tracks valid grid points \n",
    "        contributing to each latitude bin (default: False).\n",
    "    model : bool, optional\n",
    "        Set to True for model data (default). If False, allows flexibility \n",
    "        for observational data input (currently handled the same way).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    var_out : np.ndarray\n",
    "        Mean value of the binned meteorological variable along the ice-edge-normal direction. \n",
    "        Shape depends on input:\n",
    "          - (2 * nlat, ntime) for 2D variable input\n",
    "          - (vertical_levels, 2 * nlat, ntime) for 3D variable input\n",
    "    ice_out : np.ndarray\n",
    "        Corresponding mean sea ice fraction in each bin.\n",
    "    count_out : np.ndarray, optional\n",
    "        (Returned only if outputcount=True)\n",
    "        Number of valid samples contributing to each bin.\n",
    "    \"\"\"\n",
    "\n",
    "    for j in range(ntime):  # Loop over time steps\n",
    "        # Select the sea ice field for this time\n",
    "        if model:\n",
    "            ice = ice_achv[j, :, :]\n",
    "        else:\n",
    "            ice = ice_achv[j, :, :]  # (Same here, placeholder for observational logic)\n",
    "\n",
    "        # Extract variable field for the same time step\n",
    "        var = var_achv[j]  # e.g., cloud fraction or temperature\n",
    "        \n",
    "        ndim = var.ndim  # Check if var is 2D (lat, lon) or 3D (level, lat, lon)\n",
    "\n",
    "        # Loop over longitudes to analyze latitudinal structure\n",
    "        for i in range(nlon):\n",
    "            tmp = ice[:, i]  # Sea ice concentration along a latitude column\n",
    "\n",
    "            if ndim == 3:\n",
    "                # For 3D variables, select vertical profiles at this longitude\n",
    "                var_tmp = var[:, :, i]\n",
    "                nh = var_tmp.shape[0]  # Number of vertical levels\n",
    "            else:\n",
    "                # For 2D variables, select latitudinal transect at this longitude\n",
    "                var_tmp = var[:, i]\n",
    "\n",
    "            # Identify indices of sea ice vs. open ocean based on a 50% threshold\n",
    "            if hem == 'nh':\n",
    "                ind1 = np.where(tmp <= 0.5)[0]  # Ice-covered points\n",
    "                ind2 = np.where(tmp > 0.5)[0]   # Open-water points\n",
    "            else:\n",
    "                ind1 = np.where(tmp > 0.5)[0]\n",
    "                ind2 = np.where(tmp <= 0.5)[0]\n",
    "\n",
    "            n1 = ind1.size  # Number of ice points\n",
    "            n2 = ind2.size  # Number of open-water points\n",
    "\n",
    "            if i == 0:\n",
    "                tmp0 = np.full((2 * nlat), -999.)\n",
    "                tmp0[nlat - n1 : nlat] = tmp[ind1]   # Ice-covered section\n",
    "                tmp0[nlat : nlat + n2] = tmp[ind2]   # Open-water section\n",
    "\n",
    "                count0 = np.full((2 * nlat), 1.)     # Initialize counts\n",
    "\n",
    "            if ndim == 3:\n",
    "                # For 3D fields: allocate (level × latitude) array\n",
    "                var_tmp0 = np.full((nh, 2 * nlat), -999.)\n",
    "                var_tmp0[:, nlat - n1 : nlat] = var_tmp[:, ind1]\n",
    "                var_tmp0[:, nlat : nlat + n2] = var_tmp[:, ind2]\n",
    "            else:\n",
    "                # For 2D fields (lat × lon)\n",
    "                var_tmp0 = np.full((2 * nlat), -999.)\n",
    "                var_tmp0[nlat - n1 : nlat] = var_tmp[ind1]\n",
    "                var_tmp0[nlat : nlat + n2] = var_tmp[ind2]\n",
    "\n",
    "        # Stack additional longitudes along the third dimension\n",
    "        else:\n",
    "            tmp1 = np.full((2 * nlat), -999.)\n",
    "            tmp1[nlat - n1 : nlat] = tmp[ind1]\n",
    "            tmp1[nlat : nlat + n2] = tmp[ind2]\n",
    "\n",
    "            count1 = np.full((2 * nlat), 1.)\n",
    "\n",
    "            if ndim == 3:\n",
    "                var_tmp1 = np.full((nh, 2 * nlat), -999.)\n",
    "                var_tmp1[:, nlat - n1 : nlat] = var_tmp[:, ind1]\n",
    "                var_tmp1[:, nlat : nlat + n2] = var_tmp[:, ind2]\n",
    "            else:\n",
    "                var_tmp1 = np.full((2 * nlat), -999.)\n",
    "                var_tmp1[nlat - n1 : nlat] = var_tmp[ind1]\n",
    "                var_tmp1[nlat : nlat + n2] = var_tmp[ind2]\n",
    "\n",
    "            # Combine new longitude slice with accumulated data\n",
    "            tmp0 = np.dstack((tmp0, tmp1))\n",
    "            count0 = np.dstack((count0, count1))\n",
    "            var_tmp0 = np.dstack((var_tmp0, var_tmp1))\n",
    "\n",
    "        # Replace placeholder fill values with NaNs for later averaging\n",
    "        var_tmp0[var_tmp0 == -999.] = np.nan\n",
    "        tmp0[tmp0 == -999.] = np.nan\n",
    "\n",
    "        if ndim == 2:\n",
    "            count0[np.isnan(var_tmp0)] = 0.\n",
    "        \n",
    "        # Average over longitudes to collapse the stacked dimension\n",
    "        count00 = nlon * np.nanmean(count0[0], axis=1)\n",
    "        tmp00 = np.nanmean(tmp0[0], axis=1)\n",
    "\n",
    "        # For 3D variables (with vertical levels), average over longitude\n",
    "        # Otherwise, average over latitude for 2D data\n",
    "        if ndim == 3:\n",
    "            var_tmp00 = np.nanmean(var_tmp0, axis=2)\n",
    "        else:\n",
    "            var_tmp00 = np.nanmean(var_tmp0[0], axis=1)\n",
    "\n",
    "        # Initialize output arrays on the first time step\n",
    "        if j == 0:\n",
    "            count_out = count00\n",
    "            var_out = var_tmp00\n",
    "            ice_out = tmp00\n",
    "        else:\n",
    "            # Stack new time-step results along a new axis\n",
    "            count_out = np.dstack((count_out, count00))        \n",
    "            var_out = np.dstack((var_out, var_tmp00))\n",
    "            ice_out = np.dstack((ice_out, tmp00))\n",
    "\n",
    "    # Remove dummy dimension added during stacking\n",
    "    count_out = count_out[0]\n",
    "    ice_out = ice_out[0]\n",
    "\n",
    "    # For 2D variables, remove redundant first index\n",
    "    if ndim != 3:\n",
    "        var_out = var_out[0]\n",
    "    \n",
    "    # Return depending on variable dimensionality and output settings\n",
    "    if ndim == 3:\n",
    "        return var_out, ice_out\n",
    "    else:\n",
    "        if outputcount:\n",
    "            return var_out, ice_out, count_out    \n",
    "        else:\n",
    "            return var_out, ice_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2e71df0-8016-42e3-b5af-2f9aab3ca92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start extracting\n",
      "(96, 40, 30, 56)\n",
      "Binning done\n",
      "Job accomplished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_571307/1835411665.py:133: RuntimeWarning: Mean of empty slice\n",
      "  tmp00 = np.nanmean(tmp0[0], axis=1)\n",
      "/tmp/ipykernel_571307/1835411665.py:138: RuntimeWarning: Mean of empty slice\n",
      "  var_tmp00 = np.nanmean(var_tmp0, axis=2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Start extracting\")\n",
    "print(cl_achv.shape)\n",
    "\n",
    "cl_out, ice_out = Binning_distance_from_ice_edge(ice_achv, cl_achv, ntime, nlat, nlon, 'nh')\n",
    "air_out, ice_out = Binning_distance_from_ice_edge(ice_achv, air_achv, ntime, nlat, nlon, 'nh')\n",
    "\n",
    "print(\"Binning done\")\n",
    "\n",
    "# --- Convert binned outputs to xarray DataArrays ---\n",
    "# Define the coordinate system: “distance” from ice edge and “time”.\n",
    "# The distance coordinate runs from negative (sea-ice side) to positive (open-ocean side) values.\n",
    "ds_tmp = xr.DataArray(cl_out, coords=[altitude, np.arange(-nlat + 0.5, nlat + 0.5, 1.), f0.time.values],\n",
    "                      dims=[\"altitude\", \"distance\",\"time\"]).rename('clcalipso')\n",
    "\n",
    "ds_tmp1 = xr.DataArray(ice_out, coords=[np.arange(-nlat + 0.5, nlat + 0.5, 1.), f0.time.values],\n",
    "                      dims=[\"distance\",\"time\"]).rename('seaice_conc')\n",
    "\n",
    "ds_tmp2 = xr.DataArray(air_out, coords=[level,np.arange(-nlat + 0.5, nlat + 0.5, 1.), f0.time.values],\n",
    "                      dims=[\"level\",\"distance\",\"time\"]).rename('air')\n",
    "\n",
    "# --- Combine all DataArrays into a single dataset ---\n",
    "ds_out = xr.merge([ds_tmp, ds_tmp1, ds_tmp2])\n",
    "\n",
    "#ds_out.to_netcdf(\"Binned_3D_Meteorology.nc\")\n",
    "print('Job accomplished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b4bf80-17ef-423d-a7be-7c7a1a788a98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
