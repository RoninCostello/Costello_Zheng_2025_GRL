{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e069347-f07f-44c7-af53-89008bd68e8c",
   "metadata": {},
   "source": [
    "Regridded sea ice data filtered to retain only the latitudinal bands where concentrations decrease consistently from north to south"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbb0e32-c544-4a01-8e1e-e84b814b09cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import netCDF4\n",
    "import calendar\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "import xarray as xr\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0961e368-dd51-4f27-b87d-973968c5f462",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Isolate some regional subset of regridded sea ice data\u001b[39;00m\n\u001b[1;32m      2\u001b[0m filename_si_nh \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexample_regridded_sea_ice_filenc\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m f_si_nh \u001b[38;5;241m=\u001b[39m \u001b[43mxr\u001b[49m\u001b[38;5;241m.\u001b[39mopen_dataset(filename_si_nh)\n\u001b[1;32m      4\u001b[0m f_si_nh[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mdecode_cf(f_si_nh)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m f_si_nh \u001b[38;5;241m=\u001b[39m f_si_nh\u001b[38;5;241m.\u001b[39msel(time\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2007\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2014\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xr' is not defined"
     ]
    }
   ],
   "source": [
    "#Isolate some regional subset of regridded sea ice data\n",
    "filename_si_nh = 'example_regridded_sea_ice_filenc'\n",
    "f_si_nh = xr.open_dataset(filename_si_nh)\n",
    "f_si_nh['time'] = xr.decode_cf(f_si_nh)['time']\n",
    "f_si_nh = f_si_nh.sel(time=slice('2007', '2014'))\n",
    "si_nh = f_si_nh.siconc\n",
    "si_nh = si_nh.sel(lat=slice(60, 90))\n",
    "\n",
    "# Initialize an empty list to store valid longitudes for each time step\n",
    "all_strictly_increasing_lons = []\n",
    "\n",
    "# Time step is months (2007-2014 = 8 years = 96 months) \n",
    "for time_step in range(96):\n",
    "    # Select the time step\n",
    "    first_time_step = si_nh.isel(time=time_step)\n",
    "\n",
    "    # Initialize a list to store valid longitudes for this time step\n",
    "    strictly_increasing_lons = []\n",
    "\n",
    "    # Iterate over each longitude in the dataset\n",
    "    for lon in first_time_step.lon.values:\n",
    "        prime_meridian_si = first_time_step.sel(lon=lon, method=\"nearest\")  # Select nearest longitude\n",
    "\n",
    "        # Skip if the entire longitude slice is NaN\n",
    "        if prime_meridian_si.isnull().all():\n",
    "            continue\n",
    "\n",
    "        # Calculate the differences in sea ice concentration along the latitude axis\n",
    "        differences = prime_meridian_si.diff(dim='lat')\n",
    "        values = prime_meridian_si.values  # Extract the array of sea ice concentrations\n",
    "\n",
    "        # Check for negative differences, but ignore cases where:\n",
    "        # - Both the current and previous values are >= 95\n",
    "        # - Either the current or previous value is < 1\n",
    "        # There tends to be small deviations both positive and negative in concentration close to values of 0% and 100% which will eliminate an entire\n",
    "        # latitude band unnecessarily\n",
    "        errors = [\n",
    "            i for i in range(len(differences))\n",
    "            if differences[i] < 0 and not (\n",
    "                (values[i] >= 90 and values[i + 1] >= 90) or\n",
    "                (values[i] < 5 or values[i + 1] < 5)\n",
    "            )\n",
    "        ]\n",
    "        if errors:\n",
    "            print(f\"Sea ice concentrations are not strictly increasing at longitude {lon} during time step {f_si_nh.time[time_step].values}.\")\n",
    "        else:\n",
    "            print(f\"Sea ice concentrations are strictly increasing at longitude {lon} during time step {f_si_nh.time[time_step].values}.\")\n",
    "\n",
    "        # Add to valid longitudes if no errors found\n",
    "        if not errors:\n",
    "            strictly_increasing_lons.append(lon)\n",
    "\n",
    "    # Store the valid longitudes for the current time step\n",
    "    all_strictly_increasing_lons.append(strictly_increasing_lons)\n",
    "\n",
    "# Initialize an empty list to store the filtered sea ice data for each time step\n",
    "filtered_data = []\n",
    "\n",
    "# Loop over the 8 years to filter and save valid and invalid longitudes\n",
    "for time_step in range(96):\n",
    "    # Select the time step\n",
    "    first_time_step = si_nh.isel(time=time_step).copy()\n",
    "\n",
    "    # Set values to NaN for longitudes that do not meet the strictly increasing condition\n",
    "    for lon in si_nh.lon.values:\n",
    "        if lon not in all_strictly_increasing_lons[time_step]:\n",
    "            first_time_step.loc[{'lon': lon}] = np.nan  # Set to NaN for invalid longitudes\n",
    "\n",
    "    # Append the filtered data for this time step\n",
    "    filtered_data.append(first_time_step)\n",
    "\n",
    "# Concatenate the filtered data for all time steps along the 'time' dimension\n",
    "filtered_sea_ice_data = xr.concat(filtered_data, dim='time')\n",
    "\n",
    "# Create a new xarray Dataset for the filtered sea ice data (without interpolation)\n",
    "sea_ice_dataset = xr.Dataset(\n",
    "    {\n",
    "        'sea_ice_concentration': (['time', 'lat', 'lon'], filtered_sea_ice_data.values)\n",
    "    },\n",
    "    coords={\n",
    "        'lat': filtered_sea_ice_data.lat.values,\n",
    "        'lon': filtered_sea_ice_data.lon.values,\n",
    "        'time': filtered_sea_ice_data.time.values\n",
    "    }\n",
    ")\n",
    "\n",
    "output_filename = 'example_filtered_sea_ice.nc'\n",
    "\n",
    "sea_ice_dataset.to_netcdf(output_filename)\n",
    "\n",
    "print(f\"Filtered sea ice data saved to {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3e73ff-0de8-40e7-ab8b-aabd66c10547",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0fffe3-524f-477d-9096-bae88c999658",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
